{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bef26a4",
   "metadata": {},
   "source": [
    "# Complex datasets\n",
    "\n",
    "Now lets work with a much larger and more realistic dataset, just to get a feel for what working with big data is like. This will help you get the hang of working with datasets that share multiple coordinates and that have high complexity.\n",
    "\n",
    "We are going to be using current oceanic wave modelling projections from NOAA, using their sophisticated WAVEWATCH IIIÂ® (Tolman 1997, 1999a, 2009) model. See [the central model page](https://polar.ncep.noaa.gov/waves/wavewatch/) for more info.\n",
    "\n",
    "This will also allow us to demonstrate the use of OpenDAP access to big datasets over http, which is an awesome feature for working with big data that allows lazy dataset loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f75fa-be51-43e7-87e3-e2a31f490198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# The jupyter notebook is launched from your $HOME directory.\n",
    "# Change the working directory to the folder\n",
    "# which was created in your username directory under /scratch/vp91\n",
    "\n",
    "#TODO \n",
    "os.chdir(os.path.expandvars(\"/scratch/vp91/$USER/Data-Analytics/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.animation as animation \n",
    "# plotting\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "import cartopy.crs as ccrs\n",
    "import geoviews\n",
    "\n",
    "# note adapted from pangeo example gallery "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107cad81-53ed-4ee3-8333-9907398d7c33",
   "metadata": {},
   "source": [
    "Using `xarray.open_mfdataset()` function we can combine multiple netCDF files as one Xarray dataset object. Here we use `*` in `datapath` for pattern matching to select all files those names ending with `.nc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34788367",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/scratch/vp91/AAPP2023/Data/sea_surf_temp_data/*.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1835b",
   "metadata": {},
   "source": [
    "Lets open our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6795647",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset(data_path)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597f0cf8",
   "metadata": {},
   "source": [
    "## Breaking down our dataset\n",
    "\n",
    "Okay wow that looks complicated. Lets break it down one by one. \n",
    "\n",
    "Firstly it's important to note that our dataset will be lazily loaded over the network when we index it to save transferring GBs worth of data in one hit. See the [xarray page on input/output](https://docs.xarray.dev/en/stable/user-guide/io.html) for more details.\n",
    "\n",
    "First lets look at how big it is and our data variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.nbytes/1e9 #GBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74becb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c722753f",
   "metadata": {},
   "source": [
    "We have 1 variable in our dataset. This table really highlights the strenghts of xarray, that is working with **labelled multidimensional data**. \n",
    "\n",
    "Also examine the **metadata** of this dataset by looking at the `attributes`.\n",
    "\n",
    "Note in the right hand coloumn what `coords` the data corresponds to. For example an entry like:\n",
    "\n",
    "```\n",
    "sst                                           (time1, lat, lon) float32 ...\n",
    "\n",
    "```\n",
    "\n",
    "indicates that the `sst` variable exists on the `time1, lat and lon ` coordinates. In other words it is time dependent 3D data on the surface of the earth as we might expect. \n",
    "\n",
    "Lets have a closer look at this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f98660",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'sst'\n",
    "ds[var]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c2319",
   "metadata": {},
   "source": [
    "As we might expect it is our familiar `DataArray`! It has the expected dimensions and a whole bunch of metadata. Lets investigate our dataset coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d425fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a7bc2",
   "metadata": {},
   "source": [
    "We have latitude, longitude, and a time variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9bbf46-909f-4af2-a4e6-de33b97cae66",
   "metadata": {},
   "source": [
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad940dd",
   "metadata": {},
   "source": [
    "Now that we known whats happening with our dataset lets make some plots! We are going to use `hvplot` a high level plotting utility based on `Bokeh` that supports the kind of global map we want.\n",
    "\n",
    "We will plot in some of the data by slicing the array. Note that the interactive plot is best played with once an other computation is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e8b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[var][:,:,:].hvplot(x='lon', y='lat', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb30e2f",
   "metadata": {},
   "source": [
    "Wow that was simple! This shows the power of  `xarray` and its associated stacks that enable easy manipulation of complex data. We can also use `cartopy` to get a global orthographic projection that we can center on Australia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = ccrs.Orthographic(central_longitude=120, central_latitude=-30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d349ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[var][0:-1:1000,:,:].hvplot(x='lon', y='lat',\n",
    "                            cmap='rainbow', coastline=True, geo=True,\n",
    "                            project=True, projection=crs, rasterize=True,\n",
    "                            widget_type='scrubber', widget_location='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537bed58",
   "metadata": {},
   "source": [
    "Note that the time scrubber doesn't work for the above plot due to some hvplot peculiarities, but you can make a movie  by saving the images and then gluing them together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995498ad",
   "metadata": {},
   "source": [
    "Now that we have explored our dataset, lets do a few operations.\n",
    "\n",
    "Due to some pecularities of WaveWatch III that I don't quite understand, the time dimension can sometimes be `time` or sometimes `time1`. Lets figure out which one it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209214c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvar = [var for var in ds[var].dims if \"time\" in var]\n",
    "tvar = tvar[0]\n",
    "tvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315ded5",
   "metadata": {},
   "source": [
    "this is the timespan that our dataset runs over, its in 3 hour increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7120aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst.nbytes/1e9 #GBs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97583cb7",
   "metadata": {},
   "source": [
    "Lets take a latitudinal slice and show the variation in sst over time and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aedb686",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst.sel(lat=82.0).plot(x=\"lon\", y=tvar, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1340e3",
   "metadata": {},
   "source": [
    "## Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b94cfb",
   "metadata": {},
   "source": [
    "One of xarray's very powerful tools tools is the ability to use the \"split-apply-combine\" paradigm which should be familiar to users of pandas. \n",
    "\n",
    "Here we group by day by using the `.day` attribute of the `datetime64` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = ds[\"sst\"].groupby(tvar +'.year')\n",
    "gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67686fa4",
   "metadata": {},
   "source": [
    "Awesome! We got a gropuby object back that allows us to do operations over the grouped dataset.\n",
    "\n",
    "Lets go ahead and do that by computing a mean across the last 10 years. We do this with the usual syntax on the `GroupBy` object. \n",
    "\n",
    "Note that this computation is **quite expensive** and can take a while. If you are taking this course in tandem with the  `Dask` component, we will explore ways to make this computation faster later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.mean(dim=tvar)[-11:,:,:].hvplot(x='lon', y='lat', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d577b",
   "metadata": {},
   "source": [
    "Neat, we now have a daily average for our `Wind_speed_surface` variable.  Hopefully the interactive plot should be working for everyone.\n",
    "\n",
    "We are not going to cover much more on computations on this large dataset as they can be a bit slow. The sky is the limit however and `xarray` comes with lots of built in super useful stuff for us, such as methods for computing rolling averages using `.rolling()` and the capacity to do almost anything you can do in numpy and/or pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534e11b",
   "metadata": {},
   "source": [
    "## Working with time, resampling and interpreting\n",
    "\n",
    "Sometimes the timesteps we want to examine are larger or smaller than the data we have. We can use `resample` to downsample or upsample our data and `interp` to estimate the value at new timepoints that were not observed.\n",
    "\n",
    "First lets downsample into 3 months intervals.\n",
    "\n",
    "This is different from grouping as we have the flexibility to aggregate over different timeperiods. However we cannot use resample to group by values in categorical columns as you can do with `groupby`. I like to think of resample as a row wise aggregation only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_downsample = ds.sst.resample(time='3m').mean(tvar)\n",
    "ds_downsample.hvplot(x='lon', y='lat', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e2e942",
   "metadata": {},
   "source": [
    "We can use resample to upsample  as well. Here we do it over 7 days intervals, slightly more then the 1 month intervals in the model using a linear interpolation. Note that we didn't have to specify an aggregator, but instead an interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_upsample = ds.sst.resample(time='7d').interpolate(\"linear\")\n",
    "ds_upsample.hvplot(x='lon', y='lat', cmap='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557dcb43",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Perform an upsample to an even finer resolution (not too fine) and use a quadratic interpolation. You can also make a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cedf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72012b",
   "metadata": {},
   "source": [
    "<details><summary><b>Solution</b></summary>\n",
    "   <pre>\n",
    "    <br> ds_upsample = ds.sst.resample(time='12h').interpolate(\"qudratic\")\n",
    "ds_upsample.hvplot(x='lon', y='lat', cmap='rainbow')\n",
    "   </pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c1d18",
   "metadata": {},
   "source": [
    "Down and upsampling is super powerfull and was again super easy all things considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc61afad",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You have now worked with big data and complex `xarray` datasets in a large oceanographic model.  You are hopefully now familiar with all the basic concepts of `xarray`. Of course there are more details in the manual, but hopefully this is enough to get you started. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c07690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
